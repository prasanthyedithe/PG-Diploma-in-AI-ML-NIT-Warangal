{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational chatbot Demo\n",
    "### rasa 2.0.0\n",
    "1. conda create env --name rasa python=3.6\n",
    "2. Rasa (pip install rasa==2.0.0)\n",
    "3. SpaCy Language Model (pip install spacy==2.2.4)\n",
    "4. nest_asyncio (pip install nest_asyncio)  -- needed to train in a Jupyter notebook\n",
    "\n",
    "### rasa 3.2.6\n",
    "1. conda create env --name rasa --clone base  (anaconda 2022.05 base has python 3.9.12)\n",
    "2. pip install rasa (installed rasa==3.2.6)\n",
    "3. pip install spacy (installed spacy==3.4.1)\n",
    "4. pip install nest_asyncio  (needed to train in a Jupyter notebook)\n",
    "\n",
    "### rasa 3.5.6\n",
    "1. conda create env --name rasa3 --clone base  (anaconda 2022.05 base has python 3.9.12)\n",
    "2. pip install rasa[spacy] (installed rasa 3.5.6  and spacy 3.4.4)\n",
    "3. pip install nest_asyncio  (needed to train in a Jupyter notebook)\n",
    "\n",
    "- https://rasa.com/docs/rasa/jupyter-notebooks/\n",
    "- https://rasa.com/docs/rasa/tuning-your-model/\n",
    "- https://rasa.com/blog/rasa-nlu-in-depth-part-1-intent-classification/\n",
    "- https://rasa.com/blog/10-best-practices-for-designing-nlu-training-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "print(\"Event loop ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, io, json, warnings\n",
    "# logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rasa: 3.5.6 spacy: 3.4.4\n",
      "rasa.nlu: 3.5.6 rasa.core: 3.5.6\n",
      "Loading spaCy language model...\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "import rasa\n",
    "import rasa.nlu\n",
    "import rasa.core\n",
    "import spacy\n",
    "print(\"rasa: {} spacy: {}\".format(rasa.__version__, spacy.__version__))\n",
    "print(\"rasa.nlu: {} rasa.core: {}\".format(rasa.nlu.__version__, rasa.core.__version__))\n",
    "\n",
    "print(\"Loading spaCy language model...\")\n",
    "print(spacy.load(\"en_core_web_md\")(\"Hello world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for printing json data with proper indenting\n",
    "def pprint(o):   \n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of \n",
    "* NLU training files - nlu.md, stories.md\n",
    "* Config file - config.yml  (now the config file contains policies also..older versions of Rasa had a separate policy.yml file)\n",
    "* Domain file - domain.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: config.yml\n",
      "nlu.yml,stories.yml: data/\n",
      "domain: domain.yml\n",
      "models: models/\n"
     ]
    }
   ],
   "source": [
    "configfile = \"config.yml\"\n",
    "training_files = \"data/\"\n",
    "domainfile = \"domain.yml\"\n",
    "outputdir = \"models/\"\n",
    "print(\"config:\",configfile)\n",
    "print(\"nlu.yml,stories.yml:\", training_files)\n",
    "print(\"domain:\", domainfile)\n",
    "print(\"models:\", outputdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Dialogue (core) and NLU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain.yml config.yml data/ models/\n"
     ]
    }
   ],
   "source": [
    "print(domainfile, configfile, training_files, outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The configuration for pipeline and policies was chosen automatically. It was written into the config file at 'config.yml'.\n",
      "Your Rasa model is trained and saved at 'models\\20230604-084403-beveled-deque.tar.gz'.\n",
      "TrainingResult(model='models\\\\20230604-084403-beveled-deque.tar.gz', code=0, dry_run_results=None)\n"
     ]
    }
   ],
   "source": [
    "import rasa\n",
    "model_path = rasa.train(domainfile, configfile, [training_files], outputdir)\n",
    "#model_path = rasa.train(domainfile, configfile, ['data/',['data/nlu.md', 'data/stories.md'], outputdir)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bot chat - simple method using the rasa.jupyter.chat module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models\\\\20230604-084403-beveled-deque.tar.gz'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rasa.jupyter import chat\n",
    "# endpoints = \"endpoints.yml\"\n",
    "# # chat(model_path, endpoints)\n",
    "# chat(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bot chat - using the libraries - more flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa.core.agent import Agent\n",
    "#from rasa.core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa.core.utils import EndpointConfig\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Action server\n",
    "In the project directory where actions.py is defined, run at command prompt: \"rasa run actions\" --  this will start the \"action server\" which will serve the actions at http://localhost:5055/webhook\n",
    "* You can see the actions served at: http://localhost:5055/actions\n",
    "* You can check the status of the actions server at: http://localhost:5055/health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global agent\n",
    "#interpreter = NaturalLanguageInterpreter.create('models/nlu/default/current')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "#agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "# agent = Agent.load(model_path, action_endpoint = endpoint)\n",
    "agent = Agent.load(model_path[0], action_endpoint = endpoint)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Text, List, Dict, Any\n",
    "\n",
    "async def parse(text: Text):\n",
    "    global agent\n",
    "    response = await agent.handle_text(text)\n",
    "    return response\n",
    "\n",
    "def botResponse(userMsg):\n",
    "    global agent\n",
    "    if agent.is_ready():\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        responses = loop.run_until_complete(parse(userMsg))\n",
    "\n",
    "    if responses is not None :\n",
    "        return responses\n",
    "    else:\n",
    "        return ['The response was not valid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********  Bot is ready to talk! Type your messages here or send 'stop' ******* \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user :  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot : Hello None, How are you doing?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user :  I am nikhil\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot : Hi Nikhil. What news do you want to have today?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user :  can you give me some news on technology\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot : I can definitely help you. The top 5 news of the technology\n",
      "\n",
      "Bot : 1.His cockpit warning system, which alerts the crew if an aircraft is heading toward a mountain, a building or the ocean, has saved thousands of lives.\n",
      "\n",
      "Bot : 2.An A.I.-powered version of  Photoshop and the image generator Midjourney live up to the hype.\n",
      "\n",
      "Bot : 3.Interest in the futuristic, immersive digital world is fading just as Apple plans to debut a virtual reality device.\n",
      "\n",
      "Bot : 4.The District of Columbia accused the company of sharing user data in deceptive ways. A Superior Court decision said Meta had made its policies clear.\n",
      "\n",
      "Bot : 5.Regulators said the tech giant kept children’s Alexa voice recordings “forever,” violating a children’s privacy law.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user :  howdy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot : Hey Nikhil, how are you?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user :  I am fine, how are you doing today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot : I'm doing great. Tell me How can I help you today?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user :  stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...came out of bot\n"
     ]
    }
   ],
   "source": [
    "#messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "print(\"**********  Bot is ready to talk! Type your messages here or send 'stop' ******* \")\n",
    "while True:\n",
    "    a = input(\"user : \")\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    # responses = agent.handle_text(a)\n",
    "    responses = botResponse(a)\n",
    "    for response in responses:\n",
    "        print(\"Bot :\",response[\"text\"])\n",
    "        print()\n",
    "\n",
    "# Tell me some news about fashion\n",
    "print(\"Done...came out of bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayank\\anaconda3\\envs\\rasa3\\lib\\site-packages\\botocore\\httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext\n",
      "2023-06-04 09:12:15 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.core.visualize\u001b[0m  - Starting to visualize stories...\n",
      "\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks:   0%|          | 0/16 [00:00<?, ?it/s, # trackers=1]\n",
      "Processed story blocks: 100%|##########| 16/16 [00:00<00:00, 3200.08it/s, # trackers=1]\n",
      "C:\\Users\\mayank\\anaconda3\\envs\\rasa3\\lib\\site-packages\\pkg_resources\\__init__.py:1130: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\n",
      "  return get_provider(package_or_requirement).get_resource_filename(\n",
      "2023-06-04 09:12:16 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.core.visualize\u001b[0m  - Finished graph creation. Saved into file://C:\\Edureka\\course-AI-ML-PGP\\05-Natural Language Processing\\04-Building an Intent Based RASA Chatbot\\ConvChatbotRasa3.x\\graph.html\n"
     ]
    }
   ],
   "source": [
    "!rasa visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasa3",
   "language": "python",
   "name": "rasa3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
